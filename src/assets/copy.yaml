intro:
  lesson_num: "Lesson 1"
  lesson_title: "The K-Nearest Neighbors Algorithm"
  preamble: "In this lesson:"
  goals:
    - "Identify classification problems"
    - "Use the K-Nearest Neighbors (KNN) machine learning algorithm to solve
    classification problems"
    - "Tune models by adjusting hyperparameters"
    - "Measure how well your model performed using its accuracy"
part1:
  step1:
    heading: "The Dataset"
    texta:
      "For this lesson, we’ll use this dataset of property sales. It has one row per
      property sold, and columns with some information about each property."
    textb:
      "Take a moment to explore the dataset."
  step2:
    heading: "Classification"
    texta:
      "A common task in machine learning is to train a computer to distinguish
      between different groups, or classes."
    textb:
      "In our dataset, each row is either a house or an apartment.
      These 2 groups (house & apartment) will be our classes."
  step3:
    heading: "Mystery Values"
    texta:
      "This data comes from a popular real estate listings website. Sometimes, the
      website’s users don’t fill out the 'property type' field, so there are some
      rows that have a missing value in that column."
    textb:
      "How could we train a computer to predict whether a new row is a house or an
      apartment?"
  step4:
    heading: "Classifying Mystery Values"
    texta:
      "The task above is asking us to train a computer to determine the class of a
      new row. This kind of task is called a classification task. We will solve it
      by using a classification algorithm."
    textb:
      "But first, let’s take a step back and graph this data. We’ll create a
      scatterplot, with a horizontal axis representing the property size, and a
      vertical axis representing the property price."

part2:
  step1:
    "Red dots are houses, blue ones are apartments"
  step1a:
    "We've added a few more datapoints from the same dataset, to make this
    more interesting."
  step1b:
    "What a beautiful scatterplot! Now that we have the data plotted, let’s
    introduce the K-Nearest Neighbors algorithm to solve our classification task."
  step2:
    "Let’s say we have this new datapoint— a property that sold for $XXX
    thousand, and has 720 square feet of space."
  step2a:
    "The K-Nearest Neighbors algorithm will look at the nearest neighbors of
    this new datapoint, and will tally up how many of them are houses, and how
    many are apartments."
  step3:
    "How many neighbors will KNN look at?"
  step3a:
    "That’s what K stands for! It’s the number of nearest neighbors to tally up!
    Let’s say that K is 5 for now."
  step4:
    "How does KNN know which datapoints are the nearest neighbors?"
  step4a:
    "It calculates the distance from the new datapoint, (at location $XXX k, 5)
    to every other datapoint on the grid. Then it chooses the top 5."
  step5:
    "Then it will take the majority vote of those 5 datapoints, and that is the
    algorithm’s guess about what the mysterious new datapoint is."
  step5a:
    "In this case, 4/5 of the nearest neighbors are apartments— so our best
    guess is that this new datapoint is an apartment."
